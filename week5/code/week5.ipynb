{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b189babc",
   "metadata": {},
   "source": [
    "# Week 5: Pharmacogenomics Analysis\n",
    "\n",
    "## Analysis Pipeline\n",
    "1. Download reference genome (chromosome 10)\n",
    "2. Align Illumina and PacBio reads with minimap2\n",
    "3. Call variants with bcftools\n",
    "4. Phase variants with HapCUT2\n",
    "5. Compare VCFs and identify discordant variants\n",
    "6. Determine star-alleles using PharmVar database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e7094",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import urllib.request\n",
    "import shutil\n",
    "import bz2\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e513b54",
   "metadata": {},
   "source": [
    "### Set up working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c05f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path.cwd()\n",
    "data_dir = notebook_dir / \"data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Working directory: {notebook_dir}\")\n",
    "print(f\"Data directory: {data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa2819",
   "metadata": {},
   "source": [
    "## Step 1: Download Reference Genome (Chromosome 10)\n",
    "\n",
    "All target genes are located on chromosome 10:\n",
    "- CYP2C8\n",
    "- CYP2C9\n",
    "- CYP2C19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a145cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download chromosome 10 reference genome\n",
    "chr10_url = \"https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/chr10.fa.gz\"\n",
    "chr10_gz_path = data_dir / \"chr10.fa.gz\"\n",
    "chr10_fa_path = data_dir / \"chr10.fa\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DOWNLOADING REFERENCE GENOME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not chr10_fa_path.exists():\n",
    "    print(f\"Downloading chromosome 10 from UCSC Genome Browser\")\n",
    "    print(f\"Source: {chr10_url}\")\n",
    "    print(f\"Target: {chr10_gz_path}\")\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(chr10_url, chr10_gz_path)\n",
    "        print(\"Download complete!\")\n",
    "        \n",
    "        print(f\"Decompressing {chr10_gz_path.name}...\")\n",
    "        with gzip.open(chr10_gz_path, 'rb') as f_in:\n",
    "            with open(chr10_fa_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        print(f\"Decompression complete!\")\n",
    "        print(f\"Output file: {chr10_fa_path}\")\n",
    "        \n",
    "        # Remove compressed file to save space\n",
    "        chr10_gz_path.unlink()\n",
    "        print(f\"Removed compressed file: {chr10_gz_path}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during download: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Reference genome already exists: {chr10_fa_path}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download_data",
   "metadata": {},
   "source": [
    "### Download Sequencing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_sequencing_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Illumina data\n",
    "illumina_url = \"https://github.com/inumanag/fall25-csc-bioinf/raw/refs/heads/main/week4/data/illumina.fq.bz2\"\n",
    "illumina_bz2_path = data_dir / \"illumina.fq.bz2\"\n",
    "illumina_fq_path = data_dir / \"illumina.fq\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DOWNLOADING ILLUMINA SEQUENCING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not illumina_fq_path.exists():\n",
    "    print(f\"Downloading Illumina data from GitHub\")\n",
    "    print(f\"Source: {illumina_url}\")\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(illumina_url, illumina_bz2_path)\n",
    "        print(\"Download complete!\")\n",
    "        \n",
    "        print(f\"Decompressing {illumina_bz2_path.name}...\")\n",
    "        with bz2.open(illumina_bz2_path, 'rb') as f_in:\n",
    "            with open(illumina_fq_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        print(f\"Decompression complete!\")\n",
    "        print(f\"Output file: {illumina_fq_path}\")\n",
    "        \n",
    "        # Remove compressed file\n",
    "        illumina_bz2_path.unlink()\n",
    "        print(f\"Removed compressed file: {illumina_bz2_path}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during download: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Illumina data already exists: {illumina_fq_path}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Download PacBio data\n",
    "pacbio_url = \"https://github.com/inumanag/fall25-csc-bioinf/raw/refs/heads/main/week4/data/pacbio.fq.bz2\"\n",
    "pacbio_bz2_path = data_dir / \"pacbio.fq.bz2\"\n",
    "pacbio_fq_path = data_dir / \"pacbio.fq\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DOWNLOADING PACBIO SEQUENCING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not pacbio_fq_path.exists():\n",
    "    print(f\"Downloading PacBio data from GitHub\")\n",
    "    print(f\"Source: {pacbio_url}\")\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(pacbio_url, pacbio_bz2_path)\n",
    "        print(\"Download complete!\")\n",
    "        \n",
    "        print(f\"Decompressing {pacbio_bz2_path.name}...\")\n",
    "        with bz2.open(pacbio_bz2_path, 'rb') as f_in:\n",
    "            with open(pacbio_fq_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        print(f\"Decompression complete!\")\n",
    "        print(f\"Output file: {pacbio_fq_path}\")\n",
    "        \n",
    "        # Remove compressed file\n",
    "        pacbio_bz2_path.unlink()\n",
    "        print(f\"Removed compressed file: {pacbio_bz2_path}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during download: {e}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"PacBio data already exists: {pacbio_fq_path}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa2819_align",
   "metadata": {},
   "source": [
    "## Step 2: Align Illumina and PacBio reads with minimap2\n",
    "\n",
    "Align all samples in FASTQ format to chromosome 10 using minimap2 with appropriate parameters for each technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7856f",
   "metadata": {},
   "source": [
    "### Index Reference Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f992c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"INDEXING REFERENCE GENOME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "chr10_mmi_path = data_dir / \"chr10.mmi\"\n",
    "\n",
    "if not chr10_mmi_path.exists():\n",
    "    print(f\"Creating minimap2 index for {chr10_fa_path}\")\n",
    "    cmd = [\n",
    "        \"minimap2\",\n",
    "        \"-d\", str(chr10_mmi_path),\n",
    "        str(chr10_fa_path)\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "        print(result.stderr)  # minimap2 outputs to stderr\n",
    "        print(f\"Index created: {chr10_mmi_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "        print(f\"STDOUT: {e.stdout}\")\n",
    "        print(f\"STDERR: {e.stderr}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Index already exists: {chr10_mmi_path}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8ba23",
   "metadata": {},
   "source": [
    "### Align Illumina Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ALIGNING ILLUMINA READS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "illumina_sam = data_dir / \"illumina.sam\"\n",
    "illumina_bam = data_dir / \"illumina.bam\"\n",
    "illumina_sorted_bam = data_dir / \"illumina_sorted.bam\"\n",
    "illumina_bai = data_dir / \"illumina_sorted.bam.bai\"\n",
    "\n",
    "if not illumina_sorted_bam.exists():\n",
    "    print(\"Aligning Illumina reads with minimap2 (sr preset for short reads)\")\n",
    "    \n",
    "    # Align with minimap2 using short-read preset\n",
    "    align_cmd = [\n",
    "        \"minimap2\",\n",
    "        \"-ax\", \"sr\",  # short single-end reads preset\n",
    "        \"-t\", \"4\",     # threads\n",
    "        str(chr10_mmi_path),\n",
    "        str(illumina_fq_path)\n",
    "    ]\n",
    "    \n",
    "    with open(illumina_sam, 'w') as sam_file:\n",
    "        result = subprocess.run(align_cmd, stdout=sam_file, stderr=subprocess.PIPE, text=True, check=True)\n",
    "        print(result.stderr)  # minimap2 outputs to stderr\n",
    "    \n",
    "    print(f\"Alignment complete: {illumina_sam}\")\n",
    "    \n",
    "    # Convert SAM to BAM\n",
    "    print(\"Converting SAM to BAM...\")\n",
    "    subprocess.run([\n",
    "        \"samtools\", \"view\",\n",
    "        \"-b\", \"-o\", str(illumina_bam),\n",
    "        str(illumina_sam)\n",
    "    ], check=True)\n",
    "    print(f\"BAM created: {illumina_bam}\")\n",
    "    \n",
    "    # Sort BAM\n",
    "    print(\"Sorting BAM file...\")\n",
    "    subprocess.run([\n",
    "        \"samtools\", \"sort\",\n",
    "        \"-o\", str(illumina_sorted_bam),\n",
    "        str(illumina_bam)\n",
    "    ], check=True)\n",
    "    print(f\"Sorted BAM created: {illumina_sorted_bam}\")\n",
    "    \n",
    "    # Index BAM\n",
    "    print(\"Indexing BAM file...\")\n",
    "    subprocess.run([\n",
    "        \"samtools\", \"index\",\n",
    "        str(illumina_sorted_bam)\n",
    "    ], check=True)\n",
    "    print(f\"Index created: {illumina_bai}\")\n",
    "    \n",
    "    # Clean up intermediate files\n",
    "    illumina_sam.unlink()\n",
    "    illumina_bam.unlink()\n",
    "    print(\"Cleaned up intermediate files\")\n",
    "    \n",
    "    print(f\"\\nFinal output: {illumina_sorted_bam}\")\n",
    "    print(f\"Final index: {illumina_bai}\")\n",
    "else:\n",
    "    print(f\"Illumina alignment already exists: {illumina_sorted_bam}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf47b3",
   "metadata": {},
   "source": [
    "### Align PacBio Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ALIGNING PACBIO READS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pacbio_sam = data_dir / \"pacbio.sam\"\n",
    "pacbio_bam = data_dir / \"pacbio.bam\"\n",
    "pacbio_sorted_bam = data_dir / \"pacbio_sorted.bam\"\n",
    "pacbio_bai = data_dir / \"pacbio_sorted.bam.bai\"\n",
    "\n",
    "if not pacbio_sorted_bam.exists():\n",
    "    print(\"Aligning PacBio reads with minimap2 (map-pb preset for PacBio)\")\n",
    "    \n",
    "    # Align with minimap2 using PacBio preset\n",
    "    align_cmd = [\n",
    "        \"minimap2\",\n",
    "        \"-ax\", \"map-pb\",  # PacBio CLR reads preset\n",
    "        \"-t\", \"4\",         # threads\n",
    "        str(chr10_mmi_path),\n",
    "        str(pacbio_fq_path)\n",
    "    ]\n",
    "    \n",
    "    with open(pacbio_sam, 'w') as sam_file:\n",
    "        result = subprocess.run(align_cmd, stdout=sam_file, stderr=subprocess.PIPE, text=True, check=True)\n",
    "        print(result.stderr)  # minimap2 outputs to stderr\n",
    "    \n",
    "    print(f\"Alignment complete: {pacbio_sam}\")\n",
    "    \n",
    "    # Convert SAM to BAM\n",
    "    print(\"Converting SAM to BAM...\")\n",
    "    subprocess.run([\n",
    "        \"samtools\", \"view\",\n",
    "        \"-b\", \"-o\", str(pacbio_bam),\n",
    "        str(pacbio_sam)\n",
    "    ], check=True)\n",
    "    print(f\"BAM created: {pacbio_bam}\")\n",
    "    \n",
    "    # Sort BAM\n",
    "    print(\"Sorting BAM file...\")\n",
    "    subprocess.run([\n",
    "        \"samtools\", \"sort\",\n",
    "        \"-o\", str(pacbio_sorted_bam),\n",
    "        str(pacbio_bam)\n",
    "    ], check=True)\n",
    "    print(f\"Sorted BAM created: {pacbio_sorted_bam}\")\n",
    "    \n",
    "    # Index BAM\n",
    "    print(\"Indexing BAM file...\")\n",
    "    subprocess.run([\n",
    "        \"samtools\", \"index\",\n",
    "        str(pacbio_sorted_bam)\n",
    "    ], check=True)\n",
    "    print(f\"Index created: {pacbio_bai}\")\n",
    "    \n",
    "    # Clean up intermediate files\n",
    "    pacbio_sam.unlink()\n",
    "    pacbio_bam.unlink()\n",
    "    print(\"Cleaned up intermediate files\")\n",
    "    \n",
    "    print(f\"\\nFinal output: {pacbio_sorted_bam}\")\n",
    "    print(f\"Final index: {pacbio_bai}\")\n",
    "else:\n",
    "    print(f\"PacBio alignment already exists: {pacbio_sorted_bam}\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7cdb14",
   "metadata": {},
   "source": [
    "### Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6beb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"VERIFYING OUTPUT FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Illumina BAM: {illumina_sorted_bam.exists()} - {illumina_sorted_bam}\")\n",
    "print(f\"Illumina BAI: {illumina_bai.exists()} - {illumina_bai}\")\n",
    "print(f\"PacBio BAM: {pacbio_sorted_bam.exists()} - {pacbio_sorted_bam}\")\n",
    "print(f\"PacBio BAI: {pacbio_bai.exists()} - {pacbio_bai}\")\n",
    "\n",
    "if all([illumina_sorted_bam.exists(), illumina_bai.exists(), \n",
    "        pacbio_sorted_bam.exists(), pacbio_bai.exists()]):\n",
    "    print(\"\\n✓ All alignment files successfully created!\")\n",
    "else:\n",
    "    print(\"\\n✗ Some alignment files are missing!\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd8635",
   "metadata": {},
   "source": [
    "## Step 3: Call Variants with bcftools\n",
    "\n",
    "Find all variants in each sample for all genes of interest and obtain VCF files.\n",
    "\n",
    "**Expected output:** Two VCF files (one for each sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c203a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"VARIANT CALLING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTODO: Implement variant calling with bcftools\")\n",
    "print(\"This step will call variants for both Illumina and PacBio samples\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34fbed",
   "metadata": {},
   "source": [
    "## Step 4: Phase Variants with HapCUT2\n",
    "\n",
    "Phase the variant VCFs using HapCUT2 or HapTree-X.\n",
    "\n",
    "**Expected output:** Two phased VCF files (one for each sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PHASING VARIANTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTODO: Implement phasing with HapCUT2\")\n",
    "print(\"This step will phase variants from both samples\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9984d71",
   "metadata": {},
   "source": [
    "## Step 5: Compare VCFs and Identify Discordant Variants\n",
    "\n",
    "Compare the two phased VCF files and analyze discordant variants.\n",
    "\n",
    "**Expected output:** Analysis with IGV screenshots and discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"COMPARING VCFS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTODO: Compare VCFs and identify discordant variants\")\n",
    "print(\"This step will analyze shared and unique variants between technologies\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c281267",
   "metadata": {},
   "source": [
    "## Step 6: Determine Star-Alleles using PharmVar\n",
    "\n",
    "Identify star-alleles for each gene using the PharmVar database.\n",
    "\n",
    "**Expected output:** Discussion of star-allele determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STAR-ALLELE DETERMINATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTODO: Determine star-alleles using PharmVar database\")\n",
    "print(\"This step will identify CYP2C8, CYP2C9, and CYP2C19 star-alleles\")\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}